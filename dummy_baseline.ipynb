{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dummy_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxXgI2C6RFiD8xPh3q4X/w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guillaume-lrt/Covid19-retweet-prediction-challenge/blob/main/dummy_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NTj5pyuPBzd"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyRegressor"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtTMojJTPP46",
        "outputId": "50c143ee-a4dd-476c-aa07-4288fad047bd"
      },
      "source": [
        "# Load the training data\n",
        "train_data = pd.read_csv(\"https://media.githubusercontent.com/media/guillaume-lrt/Covid19-retweet-prediction-challenge/main/data/train.csv\")\n",
        "# Load the evaluation data\n",
        "eval_data = pd.read_csv(\"https://media.githubusercontent.com/media/guillaume-lrt/Covid19-retweet-prediction-challenge/main/data/evaluation.csv\")\n",
        "print(train_data)\n",
        "print(eval_data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            id  ...                                               text\n",
            "0            0  ...                                      Smh I give up\n",
            "1            1  ...  Most of us are Human Beings, but I think you m...\n",
            "2            2  ...  Old dirty tricks Trump, at it again...like we ...\n",
            "3            3  ...  Seriously..... I worked 86 hours my last check...\n",
            "4            4  ...  May ALMIGHTY ALLAH have mercy on us all. Only ...\n",
            "...        ...  ...                                                ...\n",
            "665772  665772  ...                     18 months dawg? Come on man...\n",
            "665773  665773  ...  Thank you to all of the nurses in our @Stanfor...\n",
            "665774  665774  ...  'Post it' pearls for Palliative, End of Life a...\n",
            "665775  665775  ...  His facial expressions are kind of looking for...\n",
            "665776  665776  ...                              We really can't wait.\n",
            "\n",
            "[665777 rows x 11 columns]\n",
            "            id  ...                                               text\n",
            "0       665776  ...  Coronavirus, no spring break, Chris Brown fan ...\n",
            "1       665777  ...                                This fits the data.\n",
            "2       665778  ...  Y’all talk about the Coronavirus like y’all be...\n",
            "3       665779  ...  As this coronavirus and covid-19 go on, the fo...\n",
            "4       665780  ...  Big Brother is not very good at watching you. ...\n",
            "...        ...  ...                                                ...\n",
            "285329  951105  ...  #IndianArmy fights COVID-19\\n\\n#HarKaamDeshKeN...\n",
            "285330  951106  ...  (04/22/2020) “CUT-THE-RONA” \\n\\nWe would like ...\n",
            "285331  951107  ...                                It's just starting.\n",
            "285332  951108  ...  It is in no way a surprise that one of the fou...\n",
            "285333  951109  ...            Very impressive https://t.co/xVAdPYh8IT\n",
            "\n",
            "[285334 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvaxx5viPZ7N"
      },
      "source": [
        "# Initialize the Dummy Regressor to use the Mean value of our data\n",
        "dummy_regr = DummyRegressor(strategy=\"mean\")\n",
        "# Fit the regressor with our data\n",
        "dummy_regr.fit(train_data, train_data['retweet_count'])\n",
        "# Pass the evaluation data through the predict function which just gets the same value for every tweet\n",
        "dummy_pred = dummy_regr.predict(eval_data)\n",
        "\n",
        "# Dump the results into a file that follows the required Kaggle template\n",
        "with open(\"mean_predictions.txt\", 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"TweetID\", \"NoRetweets\"])\n",
        "    for index, prediction in enumerate(dummy_pred):\n",
        "        writer.writerow([str(eval_data['id'].iloc[index]) , str(int(prediction))])\n",
        "\n",
        "# Initialize the Dummy Regressor that will constantly predicts 0 retweets\n",
        "dummy_regr = DummyRegressor(strategy=\"constant\", constant=0)\n",
        "# Fit the regressor with our data, which does nothing in action\n",
        "dummy_regr.fit(train_data, train_data['retweet_count'])\n",
        "# Pass the evaluation data through the predict function which just gets value 0 for every tweet\n",
        "dummy_pred = dummy_regr.predict(eval_data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hySgf2mjPlvT"
      },
      "source": [
        "# Dump the results into a file that follows the required Kaggle template\n",
        "with open(\"constant_predictions.txt\", 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"TweetID\", \"NoRetweets\"])\n",
        "    for index, prediction in enumerate(dummy_pred):\n",
        "        writer.writerow([str(eval_data['id'].iloc[index]) , str(int(prediction))])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb1zF65bPv0G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}