{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from verstack.stratified_continuous_split import scsplit # pip install verstack\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "from pickle import dump\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(training=-1,testing=-1,all_dataset=False):\n",
    "    pickel_in = open(\"data/train_data_preprocessed.csv\", \"rb\")\n",
    "    train_data_prepro = pickle.load(pickel_in)\n",
    "    \n",
    "    pickel_in = open(\"data/evaluation_preprocessed.csv\", \"rb\")\n",
    "    eval_data_prepro = pickle.load(pickel_in)\n",
    "#     eval_data_prepro = pd.read_csv(\"data/evaluation.csv\",error_bad_lines=False)\n",
    "\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "    sns.set(context=\"paper\")\n",
    "\n",
    "    if not all_dataset:\n",
    "        X_train, X_test, y_train, y_test = scsplit(train_data_prepro, train_data_prepro['retweet_count'], stratify=train_data_prepro['retweet_count'], train_size=0.7, test_size=0.3)\n",
    "\n",
    "        if (training != -1):\n",
    "            X_train = X_train.head(training)\n",
    "            X_test = X_test.head(testing)\n",
    "            y_train = y_train.head(training)\n",
    "            y_test = y_test.head(testing)\n",
    "            \n",
    "    else:\n",
    "        X_train = train_data_prepro\n",
    "        y_train = X_train['retweet_count']\n",
    "        X_test = -1\n",
    "        y_test = -1\n",
    "\n",
    "    # We remove the actual number of retweets from our features since it is the value that we are trying to predict\n",
    "    X_train = X_train.drop(['retweet_count'], axis=1)\n",
    "    \n",
    "    if not all_dataset:\n",
    "        X_test = X_test.drop(['retweet_count'], axis=1)\n",
    "\n",
    "    num_attribs = list(train_data_prepro[[\"user_verified\", \"timestamp_transf_hour\", \"timestamp_transf_weekday\", \"hashtags_count\", \"user_statuses_count\", \"user_followers_count\", \"user_friends_count\"]])\n",
    "    text_attribs = \"text\"\n",
    "    bin_counting_nominal_cat_attribs = \"hashtags_transf\"\n",
    "\n",
    "\n",
    "    num_pipe = Pipeline([('std_scaler', StandardScaler())])\n",
    "    text_pipe = Pipeline([('tfidf_vect', TfidfVectorizer(max_features=25, stop_words='english'))])\n",
    "    bin_counting_nominal_cat_pipe = Pipeline([('count_vect', CountVectorizer(max_features=10))])\n",
    "\n",
    "    full_pipe = ColumnTransformer([\n",
    "        ('num', num_pipe, num_attribs),\n",
    "        ('text', text_pipe, text_attribs),\n",
    "        ('bin_counting', bin_counting_nominal_cat_pipe, bin_counting_nominal_cat_attribs),\n",
    "    ])\n",
    "\n",
    "    X_train = full_pipe.fit_transform(X_train)\n",
    "    if not all_dataset:\n",
    "        X_test = full_pipe.transform(X_test)\n",
    "    X_eval = full_pipe.transform(eval_data_prepro)\n",
    "\n",
    "    print(\"SHAPE OF X_train\", X_train.shape)\n",
    "    print(\"type(X_train) = \", type(X_train))\n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"SHAPE OF y_train\", y_train.shape)\n",
    "    print(\"-----------------------------------\")\n",
    "    return X_train, X_test, y_train, y_test, X_eval\n",
    "\n",
    "\n",
    "def train(X_train,y_train):\n",
    "#     print(\"Linear Regressor\")\n",
    "#     print(\"Lasso Regressor\")\n",
    "\n",
    "    # Logistic Regression\n",
    "    print(\"LogisticRegression\")\n",
    "    log_reg = LogisticRegression(verbose = 1,multi_class='ovr',n_jobs=-1)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    return log_reg\n",
    "    \n",
    "def predict(log_reg, print_features = False, all_dataset = False):  \n",
    "    pred_log_reg_train = log_reg.predict(X_train)\n",
    "    log_reg_train_mae = mean_absolute_error(y_true=y_train, y_pred=pred_log_reg_train)        \n",
    "    print(\"Logistic Regression prediction error for training set: \", log_reg_train_mae) \n",
    "    if not all_dataset:\n",
    "        pred_log_reg_test = log_reg.predict(X_test)\n",
    "        log_reg_test_mae = mean_absolute_error(y_true=y_test, y_pred=pred_log_reg_test)\n",
    "        print(\"for testing set: \", log_reg_test_mae)\n",
    "    \n",
    "    \n",
    "    if print_features:\n",
    "        #importances = log_reg.feature_importances_\n",
    "        importance = log_reg.coef_[0]\n",
    "        for i,v in enumerate(importance):\n",
    "            print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "        # plot feature importance\n",
    "        plt.bar([x for x in range(len(importance))], importance)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE OF X_train (466043, 42)\n",
      "type(X_train) =  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "-----------------------------------\n",
      "SHAPE OF y_train (466043,)\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_eval = get_data(all_dataset=False)\n",
    "print(X_test == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2418 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3168 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4018 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4968 tasks      | elapsed: 27.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 30.009336876869202 minutes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 5618 out of 5618 | elapsed: 30.0min finished\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = train(X_train,y_train)\n",
    "print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression prediction error for training set:  144.017103571988\n",
      "for testing set:  144.77842530565653\n",
      "Feature: 0, Score: -0.78250\n",
      "Feature: 1, Score: -0.00239\n",
      "Feature: 2, Score: 0.13828\n",
      "Feature: 3, Score: -4.85270\n",
      "Feature: 4, Score: -0.01875\n",
      "Feature: 5, Score: -3.82655\n",
      "Feature: 6, Score: -0.60892\n",
      "Feature: 7, Score: -0.81596\n",
      "Feature: 8, Score: -3.39022\n",
      "Feature: 9, Score: -0.93892\n",
      "Feature: 10, Score: -1.92978\n",
      "Feature: 11, Score: -2.25520\n",
      "Feature: 12, Score: -2.79571\n",
      "Feature: 13, Score: -1.80084\n",
      "Feature: 14, Score: -1.40241\n",
      "Feature: 15, Score: -1.15867\n",
      "Feature: 16, Score: -3.02382\n",
      "Feature: 17, Score: -2.74066\n",
      "Feature: 18, Score: -2.06310\n",
      "Feature: 19, Score: -5.50067\n",
      "Feature: 20, Score: -1.32731\n",
      "Feature: 21, Score: -1.67654\n",
      "Feature: 22, Score: -1.39693\n",
      "Feature: 23, Score: -1.92753\n",
      "Feature: 24, Score: -2.07300\n",
      "Feature: 25, Score: -2.74706\n",
      "Feature: 26, Score: -1.87087\n",
      "Feature: 27, Score: -1.99124\n",
      "Feature: 28, Score: -2.01291\n",
      "Feature: 29, Score: -1.84724\n",
      "Feature: 30, Score: -2.19830\n",
      "Feature: 31, Score: -1.97635\n",
      "Feature: 32, Score: -0.01119\n",
      "Feature: 33, Score: -0.01269\n",
      "Feature: 34, Score: -0.92375\n",
      "Feature: 35, Score: -0.02514\n",
      "Feature: 36, Score: -0.00726\n",
      "Feature: 37, Score: -0.02167\n",
      "Feature: 38, Score: 2.43960\n",
      "Feature: 39, Score: -0.00708\n",
      "Feature: 40, Score: -0.00425\n",
      "Feature: 41, Score: -0.00802\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD5CAYAAAA6JL6mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAARYElEQVR4nO3dXWwU5R7H8d/Obl9Y6TJyUpqQEIhgRIKQABJNNLQmaogXIkjYKrV6IGvSCwpGGkRyFJHEmBoDJgbFFzClaBuJbxeYE2PEGBMhIohGEMMFeqGHtNsSWvuyu+eCQw9036Y7s0yf7feTkNCZzDP/+Xf76/TZ2ZlAKpVKCQBgLMvvAgAA7hDkAGA4ghwADEeQA4DhCHIAMBxBDgCGI8gBwHAhv3b8n/9cdD2GbYcVj/d5UE1poj/50aP86FF+16NH1dVVWddxRg4AhiPIAcBwBDkAGI4gBwDDEeQAYDiCHAAMR5ADgOEIcgAwnG8fCAIAvwXLQ0ok05+tE7QCSgwO+1BRYQhyABNWIpnSP1/8d9ryd7bd60M1hWNqBQAMR5ADgOEIcgAwHEEOAIYjyAHAcAQ5ABjO1eWHx48f10svvaSysjKFw2G1trYqEol4VRsAwAFXZ+TTp0/Xvn371NbWprq6Oh04cMCrugAADrk6I6+pqRn5f1lZmYLBoOuCAABj48knO7u7u9Xe3q633nrL8Ta2HXa932DQ8mScUkV/8qNH+ZVyj3r7BjMut6yAImM4Zr975DrI+/v71dzcrG3btmnq1KmOt/PiQaU8FDY3+pMfPcqvpHsUyjyLkEymxnTMRj98eXh4WJs2bVJDQ4MWLVrkZigAQIFcnZF/9tlnOnbsmC5duqT33ntPy5Yt0/r1672qDQDggKsgX7FihVasWOFRKQCAQvCBIAAwHEEOAIYjyAHAcAQ5ABiOIAcAwxHkAGA4ghwADEeQA4DhCHIAMBxBDgCGI8gBwHAEOQAYjiAHAMMR5ABgOIIcAAxHkAOA4VwH+dDQkKLRqJYsWaLDhw97URMAYAxcP3w5FApp9+7d+uCDD7yoBwAwRq7PyAOBgKZNm+ZFLQCAAjBHDgCGcz21UijbDrseIxi0PBmnVNGf/OhRfqXco96+wYzLLSugyBiO2e8e+Rbk8Xif6zFsO+zJOKWK/uRHj/Ir6R6FghkXJ5OpMR3z9ehRdXVV1nWeBHlzc7NOnTqlcDiskydPqqWlxYthAQAOeBLku3bt8mIYAEABeLMTAAxHkAOA4QhyADAcQQ4AhiPIAcBwBDkAGI4gBwDDEeQAYDiCHAAMR5ADgOEIcgAwHEEOAIYjyAHAcAQ5ABiOIAcAwxHkAGA4ghwADOc6yDs6OhSNRtXQ0KDz5897UVNRBMtDl5/PN+pfsNy3x5YCgCdcpVg8HldnZ6cOHjyon3/+Wa2treP2sW+JZEr/fPHfacvf2XavD9UAgHdcnZGfPHlSS5cuVSgU0oIFC3Tu3Dmv6gIAOOQqyHt6ejRlypSRr1OplOuCAABj42pqJRKJ6PTp0yNfW5bz3wu2HS5on/0DwxpKJCVJvX2Dsv43x10WtBSuLJNlBdK2SSZT6vt7SPv+dV/aurKgpUmTK64Z95p1FSEFAoGc447e7sq2krKum1QRyrhPJ9s6HXd0f67HPr08zmKNe/U6pz3yo3/FGnes+xzdo3z7zPXzIqmgn6Vs4yaTKaVSKVf7zJULTscNBKR//GOyo30W44TXVZAvXLhQr7/+uhKJhH755RfNnDnT8bbxeF9hOw0Fs851D/QPjnm4AenydhnGdTRmjnok5a61wG0LGdfEfZbSsRSyT2OPpVAe/2y7MZILDtl2uPBMc6i6uirrOldBbtu2VqxYoUcffVShUEg7d+50MxwAoACur72rr69XfX29F7UAAArAB4IAwHAEOQAYjiAHAMMR5ABgOIIcAAxHkAOA4QhyADAcQQ4AhiPIAcBwBDkAGI4gBwDD8ZyzIgpagYxPIApaASV8qAdAaSLIiygxOJx5+XWuA0BpY2oFAAxHkAOA4YybWrl63tmyAiOPVWLeGcBEZVyQXz3vHLnq8UomhnjON0OTPMgagDOuplb27Nmjuro6Pfnkk17VM6EkBoel4UTav2xvkgJAJq6CfNWqVdq/f79XtQAACuBqaqW6ulq///67V7XAIa5PRynidV044+bIwfXpKE28rguXN8jj8bhisVja8qamJtXW1ha8Y9sOF7ztFcGg5ck4ktTbN5i2zLICiuQZP9N2Trct1ri5jiXXuNnkW5dtXLf7LNa4puyzWOMWe58TkZdZVIi8QW7btjo6Ojzf8ZWrTdywr7pqxbVQMG1RMpnKP36G7RxvW6xxcx1LjnGzybcu27hu91mscU3ZZ7HGLfo+JyBPsyiL6uqqrOtcvdnZ2dmpzZs368SJE3r88cfV1dXlZjgAQAFczZGvXr1aq1ev9qoWAEABeLMTRccHn4DiIshRdDmvRsgyTwvAOW6aBQCGI8gBwHBMrWDC4Q6aKDUEOSYcN3fQ5I1bjEcEOTyRKeBK8QyXN24xHhHk8ESmgCu1EAfGK97sBADDEeQAYDiCHAAMR5ADgOF4sxMYZaJcgYPSQZADo3AFDkzD1AoAGI4gBwDDMbUCR3jCOTB+uQryWCym3t5eJZNJbdiwQXfddZdXdWGc4Qnn/inW/V24b0zpcBXkW7du1axZs9Td3a3GxkaCHCiCYt3fhfvGlA5XQT5r1ixJUkVFhSyL6fbx4sqZFrdovb44w4VfPJkjb21tVWNj45i2se2w6/0Gg5Yn40hSb99g2jLLCiiSZ/xM2zndttjjBoOWEonk/xeEy3OOm43bY8kl33Hm+r54cSxevoZyKeQ4r16fTf/AsPb967605WVBS5MmVxTldV0WtHLucyK6Xq+jbPIGeTweVywWS1ve1NSk2tpavfvuu7IsSw899NCYdnzlHtBu2FfdS9q1DH9KJpOp/ONn+RPU0bZFHjdjf3KMm43rY8kl33Hm+r54cCyevoZyKeA4r1k/RgOSBvoHFSwPpf2VEJCDn78c9QwMZg75K/uciK7H66i6uirrurxBbtu2Ojo6Mq775JNP9MMPP+jVV18tvDqgQCZNZfh11Q8fbpoYCp5aSSQS2rp1q+bNm6fGxkZZlqX9+/d7WRuQk0lv1nHVD4qp4CAPBoM6deqUl7UAAArAB4IApOEB1WbhmkEAaRKDw9JwQhpOKBIuH/l/tiki+Isz8gnGpDcIAThDkE8wJr1BCMAZplYAwHAEOQAYjiAHAMMR5ABgOIIcAAxHkAOA4QhyADAcQQ4AhiPIAcBwBDkAGI6P6GNcy3RvmFK8A59fD55AaSDIMWI8hslEecIND56AGwQ5RhAmgJlcBfn27dv166+/qr+/Xw8++KAee+wxr+oCADjkKsifeeYZlZeXa3h4WA888ICi0ajKy8u9qg0A4ICrq1auhPbAwIBmzJihsrIyT4oCADjneo68paVF33zzjaLRqAKBgOPtbDvsdtcKBi1PxpGk3r7BtGWWFVAkz/iZtnO6bbHH9bI/xeJ3/0zokd/oUX5+9yhvkMfjccVisbTlTU1Nqq2t1csvv6yBgQE1NjZq+fLlmjNnjqMdx+N9Y692FNsOezKOpIxPx0kmU/nHz/JUHUfbFnlcT/tTJMHyUMYrZQJy+Rpx2D8TeuQ3epTf9ehRdXVV1nV5g9y2bXV0dGRcNzg4qPLycpWXl6uyslIVFRWFV4kJiStlAPdcTa1s2LBBly5d0tDQkO677z7NmDHDq7oAAA65CvI9e/Z4VQcAoEDcawUADEeQA4DhCHIAMBxBDgCGI8gBwHDc/XCcGo+3lAUwPhHk4xQflAHgFFMrAGA4ghwADEeQA4DhCHIAMBxBDgCGI8gBwHAEOQAYjiAHAMMR5ABgOD7Z6RIfpQfgN9dn5IlEQsuXL9fbb7/tRT3GSQwOS8OJtH/ZPmIPAF5zHeSHDh3iWZ0A4CNXQT4wMKAvvvhC999/v1f1AADGyNUceVtbm9asWaPu7u4xb2vbYTe7liQFg5Yn40hSb99g2jLLCiji0fh+8LI/psn0/ZTSv6cTuUdO0aP8/O5R3iCPx+OKxWJpy2OxmL777jutW7dOhw4dGvOO4/G+MW8zmm2HPRlHkhQKpi1KJlPeje8DT/tjmgzfTyn9ezqhe+QQPcrvevSouroq67q8QW7btjo6OtKWnzhxQl1dXVq3bp3++usvDQ0Nad68ebrzzjvdVQsAGJOCp1YWLlyozs5OSZff8Ozu7ibEAcAHnlxHvnLlSi+GAQAUgE92AoDhCHIAMBxBDgCGI8gBwHAEOQAYjiAHAMMR5ABgOIIcAAxHkAOA4QhyADAcQQ4AhiPIAcBwBDkAGI4gBwDDEeQAYDiCHAAM58mDJUpB0AronW33pi1L+FQPADjlKsi3bNmiM2fO6IYbbtDcuXP17LPPelXXdZcYHE5f5kMdADBWrs/It2/frttuu82LWgAABXA9R/7CCy+ooaFB3377rRf1AADGyNUZeUtLi6ZOnao///xTTzzxhA4dOqTKykpH29p22M2uJUnBoOXJOKVqIvent28w43LLCihyVU8mco+cokf5+d2jvEEej8cVi8XSljc1Nam2tlaSVFNTo5tvvll//PGHZs+e7WjH8Xjf2CrNwLbDnoxTqiZ0f0LBjIuTydQ1PZnQPXKIHuV3PXpUXV2VdV3eILdtWx0dHRnXXbx4UVVVVerr69Nvv/2mmpqawqsEABTE1dTKU089pYsXLyqRSKipqUmTJ0/2qi4AgEOugnzv3r1e1QEAKBCf7AQAwxHkAGA4ghwADEeQA4DhCHIAMBxBDgCGI8gBwHAEOQAYjgdLoCRlelDIleXcZx6lhiBHScr0oBCJh4WgNDG1AgCGI8gBwHAEOQAYjiAHAMMR5ABgOIIcAAxHkAOA4QhyADBcIJVKpfwuAgBQOM7IAcBwBDkAGI4gBwDDEeQAYDiCHAAMR5ADgOEIcgAwnJFB3tHRoWg0qoaGBp0/f97vcsaNoaEhRaNRLVmyRIcPH5YkdXV1af369aqvr9drr73mc4X+On78uNasWaO1a9cqFoupt7eX/oxy4cIFRaNRrV27VvX19Tpz5oz+/vtvbdy4UY888oiee+45JZNJv8scF44dO6ZbbrlFXV1dvr+OjAvyeDyuzs5OtbW1afPmzWptbfW7pHEjFApp9+7damxsHFm2d+9erVq1SgcPHtSPP/6os2fP+lihv6ZPn659+/apra1NdXV1OnDgAP0Z5cYbb1R7e7va2tq0ceNGvfnmm/rwww81f/58tbe3y7Isff31136XOS7s379f8+fPl+T/z5lxQX7y5EktXbpUoVBICxYs0Llz5/wuadwIBAKaNm3aNcu+//571dXVSZJqa2t19OhRP0obF2pqajRp0iRJUllZmYLBIP0ZJRgMyrIux8LFixc1d+5cHTt2jB6N8uWXX2rx4sUKh8OS/P85My7Ie3p6NGXKlJGvucNAbn19faqsrJQkRSIR9fT0+FyR/7q7u9Xe3q6HH36Y/mRw9uxZRaNR7dixQ0uXLlVPT48ikYgkeiRJyWRS7e3tqq+vH1nm9+vIuCCPRCLq7e0d+frK2QMymzRpkgYGBiRdPsO6+pfgRNTf36/m5mZt27ZNU6dOpT8ZzJkzR++//77eeOMN7dix45qfOXokffrpp7rnnntUUVExsszv15FxKbhw4UIdPXpUiURCP/30k2bOnOl3SePa4sWL9dVXX0mSjhw5oiVLlvhckX+Gh4e1adMmNTQ0aNGiRZLoz2iDg4Mj/6+qqlJlZaVuv/12HTlyRBI9kqQzZ87o888/17p163T69Gk9/fTTvr+OjLz74cGDB/Xxxx8rFApp586dhPlVmpubderUKYXDYd19991av369WlpadOnSJd1xxx1qbm72u0TffPTRR3rxxRd16623SpKWLVumlStX0p+rHD9+XK+88ooCgYAkacuWLbrpppu0ZcsWXbhwQbNnz9bzzz/PX8L/09DQoF27dkmSr68jI4McAPB//FoFAMMR5ABgOIIcAAxHkAOA4QhyADAcQQ4AhiPIAcBwBDkAGO6/mlIjQYiNkh0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(model,print_features=True,all_dataset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the results into a file that follows the required Kaggle template\n",
    "eval_data = pd.read_csv(\"data/evaluation.csv\",error_bad_lines=False)\n",
    "\n",
    "def write_file(title = \"LogisticRegression(42_features)_all_dataset\"):\n",
    "    y_pred = model.predict(X_eval)\n",
    "    with open(title + \".txt\", 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"TweetID\", \"NoRetweets\"])\n",
    "        for index, prediction in enumerate(y_pred):\n",
    "            writer.writerow([str(eval_data['id'].iloc[index]) , str(int(prediction))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()\n",
    "idxs = np.argsort(importances)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(idxs)), importances[idxs], align='center')\n",
    "plt.yticks(range(len(idxs)), [col_names[i] for i in idxs])\n",
    "plt.xlabel('Logistic Regression Feature Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
